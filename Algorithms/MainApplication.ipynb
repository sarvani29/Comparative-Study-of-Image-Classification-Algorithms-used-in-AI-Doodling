{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.utils import print_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_checkpoint_path = \"D:\\Lectures\\sem 2\\Artificial Intelligence\\CS7IS2-project\\Kanika\\cnn_model.h5\"\n",
    "emojis_path = 'D:\\Lectures\\sem 2\\Artificial Intelligence\\CS7IS2-project\\Kanika\\emoji\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model= load_model(cnn_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "  x=28\n",
    "  y=28\n",
    "  image = cv2.resize(image, (x, y))\n",
    "  image = np.array(image, dtype=np.float32)\n",
    "  image = np.reshape(image, (-1, x, y, 1))\n",
    "  print (image)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, image):\n",
    "  processed_image = process_image(image)\n",
    "  print (\"processed image shape: \")\n",
    "  print (processed_image.shape)\n",
    "  prediction_temp = model.predict(processed_image)\n",
    "  print (\"prediction temp: \")\n",
    "  print (prediction_temp)\n",
    "  prediction = model.predict(processed_image)[0]\n",
    "  print (\"prediction: \")\n",
    "  print (prediction)\n",
    "  prediction_class = list(prediction).index(max(prediction))\n",
    "  return max(prediction), prediction_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emoji():\n",
    "#   path = '/content/drive/My Drive/Colab Notebooks/CS7IS2 - Artificial Intelligence/emoji'\n",
    "  emojis = []\n",
    "  for e in range(len(os.listdir(emojis_path))):\n",
    "    print (e)\n",
    "    emojis.append(cv2.imread(emojis_path + str(e) + '.png', -1))\n",
    "  return emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_transparent(face_img, overlay_t_img):\n",
    "  # Split out the transparency mask from the colour info\n",
    "    overlay_img = overlay_t_img[:, :, :3]  # Grab the BRG planes\n",
    "    overlay_mask = overlay_t_img[:, :, 3:]  # And the alpha plane\n",
    "\n",
    "    # Again calculate the inverse mask\n",
    "    background_mask = 255 - overlay_mask\n",
    "\n",
    "    # Turn the masks into three channel, so we can use them as weights\n",
    "    overlay_mask = cv2.cvtColor(overlay_mask, cv2.COLOR_GRAY2BGR)\n",
    "    background_mask = cv2.cvtColor(background_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Create a masked out face image, and masked out overlay\n",
    "    # We convert the images to floating point in range 0.0 - 1.0\n",
    "    face_part = (face_img * (1 / 255.0)) * (background_mask * (1 / 255.0))\n",
    "    overlay_part = (overlay_img * (1 / 255.0)) * (overlay_mask * (1 / 255.0))\n",
    "\n",
    "    # And finally just add them together, and rescale it back to an 8bit integer image\n",
    "    return np.uint8(cv2.addWeighted(face_part, 255.0, overlay_part, 255.0, 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay(img, emoji, x, y, w, h):\n",
    "  emoji = cv2.resize(emoji, (w,h))\n",
    "  try:\n",
    "    img[y:y+h, x:x+w] = blend_transparent(img[y:y+h, x:x+w], emoji)\n",
    "  except:\n",
    "    pass\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(model, np.zeros((50, 50, 1), dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emojis = get_emoji()\n",
    "# # emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower_green = np.array([110, 50, 50])\n",
    "# Upper_green = np.array([130, 255, 255])\n",
    "# points = deque(maxlen=512)\n",
    "# blackboard = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "# digit = np.zeros((200, 200, 3), dtype=np.uint8)\n",
    "# pred_class = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture = cv2.VideoCapture(0)\n",
    "# if(capture.isOpened() == False):\n",
    "#   print(\"not open\")\n",
    "# else:\n",
    "#   print (\"open\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    emojis = get_emoji()\n",
    "#     print (\"emojis: \")\n",
    "#     print (emojis)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    Lower_green = np.array([110, 50, 50])\n",
    "    Upper_green = np.array([130, 255, 255])\n",
    "    pts = deque(maxlen=512)\n",
    "    blackboard = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "    digit = np.zeros((200, 200, 3), dtype=np.uint8)\n",
    "    pred_class = 0\n",
    "\n",
    "    while (cap.isOpened()):\n",
    "        ret, img = cap.read()\n",
    "        img = cv2.flip(img, 1)\n",
    "#         cv2.imshow(\"frame1\", img)\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "#         cv2.imshow(\"frame2\", hsv)\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        mask = cv2.inRange(hsv, Lower_green, Upper_green)\n",
    "#         cv2.imshow(\"frame3\", mask)\n",
    "        mask = cv2.erode(mask, kernel, iterations=2)\n",
    "#         cv2.imshow(\"frame4\", mask)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "#         cv2.imshow(\"frame5\", mask)\n",
    "        # mask=cv2.morphologyEx(mask,cv2.MORPH_CLOSE,kernel)\n",
    "        mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "#         cv2.imshow(\"frame6\", mask)\n",
    "        res = cv2.bitwise_and(img, img, mask=mask)\n",
    "#         cv2.imshow(\"res\", res)\n",
    "        cnts, heir = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "        center = None\n",
    "        print (\"cnts: \" + str(cnts))\n",
    "        print (\"heir: \" + str(heir))\n",
    "\n",
    "        if len(cnts) >= 1:\n",
    "            cnt = max(cnts, key=cv2.contourArea)\n",
    "            if cv2.contourArea(cnt) > 200:\n",
    "                ((x, y), radius) = cv2.minEnclosingCircle(cnt)\n",
    "                \n",
    "                cv2.circle(img, (int(x), int(y)), int(radius), (0, 255, 255), 2)\n",
    "                cv2.circle(img, center, 5, (0, 0, 255), -1)\n",
    "\n",
    "                M = cv2.moments(cnt)\n",
    "                center = (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "                pts.appendleft(center)\n",
    "                for i in range(1, len(pts)):\n",
    "                    if pts[i - 1] is None or pts[i] is None:\n",
    "                        continue\n",
    "                    cv2.line(blackboard, pts[i - 1], pts[i], (255, 255, 255), 7)\n",
    "                    cv2.line(img, pts[i - 1], pts[i], (0, 0, 255), 2)\n",
    "        elif len(cnts) == 0:\n",
    "            if len(pts) != []:\n",
    "                blackboard_gray = cv2.cvtColor(blackboard, cv2.COLOR_BGR2GRAY)\n",
    "                blur1 = cv2.medianBlur(blackboard_gray, 15)\n",
    "                blur1 = cv2.GaussianBlur(blur1, (5, 5), 0)\n",
    "                thresh1 = cv2.threshold(blur1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "#                 blackboard_cnts = cv2.findContours(thresh1.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[1]\n",
    "                blackboard_cnts, h = cv2.findContours(thresh1.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "                if len(blackboard_cnts) >= 1:\n",
    "                    cnt = max(blackboard_cnts, key=cv2.contourArea)\n",
    "                    print(cv2.contourArea(cnt))\n",
    "                    if cv2.contourArea(cnt) > 2000:\n",
    "                        x, y, w, h = cv2.boundingRect(cnt)\n",
    "                        digit = blackboard_gray[y:y + h, x:x + w]\n",
    "                        pred_probab, pred_class = predict(model, digit)\n",
    "#                         print(pred_class, pred_probab)\n",
    "\n",
    "            pts = deque(maxlen=512)\n",
    "            blackboard = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "            img = overlay(img, emojis[pred_class], 400, 250, 100, 100)\n",
    "        cv2.imshow(\"Frame\", img)\n",
    "        k = cv2.waitKey(10)\n",
    "        if k == 27:\n",
    "            break\n",
    "            \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
